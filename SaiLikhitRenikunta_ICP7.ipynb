{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd9605a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Basic packages for creating dataframes and loading dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #Package for visualization\n",
    "import re #importing package for Regular expression operations\n",
    "from sklearn.model_selection import train_test_split #Package for splitting the data\n",
    "from sklearn.preprocessing import LabelEncoder #Package for conversion of categorical to Numerical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer #Tokenization (use from tensorflow.keras)\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences #Add zeros or crop based on the length\n",
    "from tensorflow.keras.models import Sequential #Sequential Neural Network\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D #For layers in Neural Network\n",
    "from tensorflow.keras.utils import to_categorical #For converting labels to categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c10e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset as a Pandas DataFrame\n",
    "dataset = pd.read_csv('Sentiment.csv')\n",
    "\n",
    "# Select only the necessary columns 'text' and 'sentiment'\n",
    "mask = dataset.columns.isin(['text', 'sentiment'])\n",
    "data = dataset.loc[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0421ec2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sai likhit\\AppData\\Local\\Temp\\ipykernel_36168\\2214349272.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text'] = data['text'].apply(lambda x: x.lower())\n",
      "C:\\Users\\sai likhit\\AppData\\Local\\Temp\\ipykernel_36168\\2214349272.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n"
     ]
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08bc1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt', ' ') #Removing Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34aa3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ') #Maximum words is 2000 to tokenize sentence\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values) #taking values to feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0aa24787",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(X) #Padding the feature matrix\n",
    "\n",
    "embed_dim = 128 #Dimension of the Embedded layer\n",
    "lstm_out = 196 #Long short-term memory (LSTM) layer neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d340e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createmodel(optimizer='adam'):\n",
    "    model = Sequential() #Sequential Neural Network\n",
    "    model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1])) #input dimension 2000 Neurons, output dimension 128 Neurons\n",
    "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)) #Drop out 20%, 196 output Neurons, recurrent dropout 20%\n",
    "    model.add(Dense(3,activation='softmax')) #3 output neurons[positive, Neutral, Negative], softmax as activation\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy']) #Compiling the model\n",
    "    return model\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0401ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder() #Applying label Encoding on the label matrix\n",
    "integer_encoded = labelencoder.fit_transform(data['sentiment']) #fitting the model\n",
    "y = to_categorical(integer_encoded)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42) #67% training data, 33% test data split\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "238e6236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sai likhit\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 - 35s - 119ms/step - accuracy: 0.6398 - loss: 0.8277\n",
      "144/144 - 4s - 31ms/step - accuracy: 0.6621 - loss: 0.7793\n",
      "The test score is: 0.7792977690696716\n",
      "the test accuracy is: 0.6620795130729675\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32 #Batch size 32\n",
    "model = createmodel() #Function call to Sequential Neural Network\n",
    "model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size, verbose = 2) #verbose the higher, the more messages\n",
    "score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size) #evaluating the model\n",
    "print(\"The test score is:\",score)\n",
    "print(\"the test accuracy is:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f39e7958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'compile_metrics']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names) #metrics of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c327ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('sentimentAnalysis.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ead6cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('sentimentAnalysis.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4d06724",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e8919c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 ... 2 0 2]\n",
      "0         Neutral\n",
      "1        Positive\n",
      "2         Neutral\n",
      "3        Positive\n",
      "4        Positive\n",
      "           ...   \n",
      "13866    Negative\n",
      "13867    Positive\n",
      "13868    Positive\n",
      "13869    Negative\n",
      "13870    Positive\n",
      "Name: sentiment, Length: 13871, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(integer_encoded)\n",
    "print(data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6605573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 2s - 2s/step\n",
      "[0.67102534 0.17469758 0.15427707]\n",
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the text data\n",
    "sentence = ['A lot of good things are happening. We are respected again throughout the world, and that is a great thing.@realDonaldTrump']\n",
    "sentence = tokenizer.texts_to_sequences(sentence) # Tokenizing the sentence\n",
    "sentence = pad_sequences(sentence, maxlen=28, dtype='int32', value=0) # Padding the sentence\n",
    "sentiment_probs = model.predict(sentence, batch_size=1, verbose=2)[0] # Predicting the sentence text\n",
    "sentiment = np.argmax(sentiment_probs)\n",
    "\n",
    "print(sentiment_probs)\n",
    "if sentiment == 0:\n",
    "    print(\"Neutral\")\n",
    "elif sentiment < 0:\n",
    "    print(\"Negative\")\n",
    "elif sentiment > 0:\n",
    "    print(\"Positive\")\n",
    "else:\n",
    "    print(\"Cannot be determined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "23ce5047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with optimizer: adam\n",
      "291/291 - 76s - 262ms/step - accuracy: 0.6391 - loss: 0.8303\n",
      "144/144 - 4s - 27ms/step - accuracy: 0.6671 - loss: 0.7758\n",
      "Optimizer: adam, Test Score: 0.7757890224456787, Test Accuracy: 0.6671035289764404\n",
      "Training with optimizer: rmsprop\n",
      "291/291 - 29s - 99ms/step - accuracy: 0.6378 - loss: 0.8350\n",
      "144/144 - 4s - 27ms/step - accuracy: 0.6667 - loss: 0.7537\n",
      "Optimizer: rmsprop, Test Score: 0.7537410855293274, Test Accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "for optimizer in ['adam', 'rmsprop']:\n",
    "    print(f\"Training with optimizer: {optimizer}\")\n",
    "    model = createmodel(optimizer=optimizer)\n",
    "    model.fit(X_train, Y_train, epochs=1, batch_size=32, verbose=2)\n",
    "    score, acc = model.evaluate(X_test, Y_test, verbose=2)\n",
    "    print(f\"Optimizer: {optimizer}, Test Score: {score}, Test Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f212c07",
   "metadata": {},
   "source": [
    "I tried using the GridSearchCV to tune model's hyperparameters suing below sample code which was mentioned in the class:\n",
    "model = KerasClassifier(build_fn=model,verbose=0)\n",
    "batch_size = [10, 20, 40]\n",
    "epochs = [1, 2, 3]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "\n",
    "But faced errors like all 45 fits failed,alueError: Sequential model 'sequential_35' has no defined outputs yet.\n",
    "\n",
    "so i manually tuned the hyperparameters using adam and rsmprop optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20958271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
